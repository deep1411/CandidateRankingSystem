{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61875b4",
   "metadata": {},
   "source": [
    "# Qwen – Finetuning/Chat Notebook (Annotated)\n",
    "*Last updated: October 28, 2025*\n",
    "\n",
    "This notebook is organized for clarity when working with **Qwen** models. Each major step is introduced with a short explanation, including chat templates via `apply_chat_template`, training, and inference.\n",
    "\n",
    "**Included:**\n",
    "- Section headers automatically injected before relevant code cells\n",
    "- Lightweight explanations for each phase\n",
    "- A simple footer with suggested next steps\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fb1e1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Table of Contents</strong></summary>\n",
    "\n",
    "1. Setup & Imports  \n",
    "2. Configuration & Constants  \n",
    "3. Environment / GPU Check  \n",
    "4. Data Loading  \n",
    "5. Exploratory Data Analysis (EDA)  \n",
    "6. Cleaning & Preprocessing  \n",
    "7. Tokenization & Chat Templates  \n",
    "8. Model Setup  \n",
    "9. Training Loop / Trainer  \n",
    "10. Evaluation & Metrics  \n",
    "11. Inference / Generation  \n",
    "12. Safety & Guardrails  \n",
    "13. Persistence & Export  \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d01c89-9d36-48f7-9d6d-9e8a6add2de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-win_amd64.whl.metadata (703 bytes)\n",
      "Downloading hf_xet-1.1.8-cp37-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 7.1 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547ad60",
   "metadata": {},
   "source": [
    "### Setup & Imports\n",
    "Import core libraries for Qwen models and utilities. Keep imports organized and remove unused ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c12d6c-1906-4615-ba3e-94ceee068257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '6891761002359d4e3841311f',\n",
       " 'name': 'bal141',\n",
       " 'fullname': 'Deepinder',\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/6f679a831597edacbec257d48e9c6ef1.svg',\n",
       " 'orgs': [],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'Ntk',\n",
       "   'role': 'fineGrained',\n",
       "   'createdAt': '2025-08-05T03:48:28.378Z',\n",
       "   'fineGrained': {'canReadGatedRepos': True,\n",
       "    'global': [],\n",
       "    'scoped': [{'entity': {'_id': '6891761002359d4e3841311f',\n",
       "       'type': 'user',\n",
       "       'name': 'bal141'},\n",
       "      'permissions': ['repo.content.read']}]}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, whoami, hf_hub_download\n",
    "\n",
    "HF_API_KEY = \"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\"\n",
    "login(token=HF_API_KEY)\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab16cdb7-6c2a-4203-bb64-c73a4e978aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json, math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bd6b7",
   "metadata": {},
   "source": [
    "### Configuration & Constants\n",
    "Centralize hyperparameters, paths, and seeds for reproducible runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67305e4b-61df-4610-b191-112e36675055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen3-0.6B\"  \n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_ID,\n",
    "    tokenizer=tok,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    return_full_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd998d",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load datasets/artifacts and validate shapes/schemas. Print sample rows to sanity-check text fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec6ac8e-1a58-49c1-99e0-4294421cc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\Users\\dbal\\anaconda_projects\\PotentialTalentsNLP\\potentialtalents.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Parse connections like \"500+\" → 500 (handles missing/NaN/ints/strings)\n",
    "def parse_connections(x):\n",
    "    if pd.isna(x): \n",
    "        return 0\n",
    "    s = str(x).strip()\n",
    "    if s.endswith(\"+\"):\n",
    "        s = s[:-1]\n",
    "    s = re.sub(r\"\\D\", \"\", s)  # keep digits only\n",
    "    return int(s) if s else 0\n",
    "\n",
    "df[\"connections_num\"] = df.get(\"connection\", 0).apply(parse_connections)\n",
    "\n",
    "# Clean job titles\n",
    "honor_pat = re.compile(r\"\\b(?:cum laude|magna cum|summa cum|dean['’]?s list|honou?rs|with honou?rs)\\b\", re.I)\n",
    "df[\"job_title_clean\"] = (\n",
    "    df[\"job_title\"].astype(str)\n",
    "      .str.replace(honor_pat, \"\", regex=True)\n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "# Convert rows → candidate dicts\n",
    "def to_candidates(rows: pd.DataFrame):\n",
    "    return [\n",
    "        {\n",
    "            \"id\": int(r[\"id\"]),\n",
    "            \"title\": str(r.get(\"job_title_clean\") or r.get(\"job_title\") or \"\"),\n",
    "            \"location\": str(r.get(\"location\", \"\")),\n",
    "            \"connections\": int(r.get(\"connections_num\", 0)),\n",
    "        }\n",
    "        for _, r in rows.iterrows()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699730f9-4599-4a52-974c-706e1d7e86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>sim_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                    job_title_clean  sim_qwen\n",
       "1    2  Native English Teacher at EPIK (English Progra...      0.98\n",
       "9   10  Seeking Human Resources HRIS and Generalist Po...      0.97\n",
       "4    5    Advisory Board Member at Celal Bayar University      0.96\n",
       "10  11                      Student at Chapman University      0.96\n",
       "0    1  2019 C.T. Bauer College of Business Graduate (...      0.95\n",
       "7    8                               HR Senior Specialist      0.95\n",
       "3    4             People Development Coordinator at Ryan      0.94\n",
       "5    6                Aspiring Human Resources Specialist      0.93\n",
       "2    3              Aspiring Human Resources Professional      0.92\n",
       "8    9  Student at Humber College and Aspiring Human R...      0.92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A) Make titles compact to keep token usage low → fewer truncation issues\n",
    "def short_title(s: str, max_words: int = 8):\n",
    "    ws = re.findall(r\"[A-Za-z0-9]+\", s or \"\")\n",
    "    return \" \".join(ws[:max_words])\n",
    "\n",
    "# B) Build one compact prompt over the entire dataset\n",
    "def build_prompt_all(df, role=\"Aspiring Human Resources Specialist\"):\n",
    "    cands = [\n",
    "        {\"id\": int(r.id), \"title\": short_title(str(r.job_title_clean))}\n",
    "        for r in df.itertuples()\n",
    "    ]\n",
    "    header = (\n",
    "        \"You are a recruiting specialist.\\n\"\n",
    "        f'Return ONLY a JSON array with exactly {len(cands)} objects '\n",
    "        '( {\"id\": <int>, \"score\": <float in [0,1]>} ), one per candidate in the SAME ORDER.\\n'\n",
    "        \"No text before or after the JSON.\\n\\nCandidates:\\n\"\n",
    "    )\n",
    "    body = \"\\n\".join([f'- id={c[\"id\"]}, title=\"{c[\"title\"]}\"' for c in cands])\n",
    "    return header + body + \"\\n\\nJSON:\"\n",
    "\n",
    "# C) Extract the first balanced [...] slice (prevents stray tokens from breaking json.loads)\n",
    "def extract_balanced_json_array(text: str) -> str:\n",
    "    start = text.find(\"[\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No '[' found in model output.\")\n",
    "    depth = 0\n",
    "    for i, ch in enumerate(text[start:], start=start):\n",
    "        if ch == \"[\":\n",
    "            depth += 1\n",
    "        elif ch == \"]\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return text[start:i+1]\n",
    "    raise ValueError(\"Unbalanced JSON array (truncated output).\")\n",
    "\n",
    "# D) Run once and attach scores\n",
    "prompt_all = build_prompt_all(df, role=\"Aspiring Human Resources Specialist\")\n",
    "\n",
    "raw = pipe(\n",
    "    prompt_all,\n",
    "    max_new_tokens=1536,                                 \n",
    "    do_sample=False,\n",
    "    pad_token_id=(pipe.tokenizer.eos_token_id\n",
    "                  if hasattr(pipe, \"tokenizer\") else None),\n",
    "    return_full_text=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "json_text = extract_balanced_json_array(raw)\n",
    "items = json.loads(json_text)                             # strict parse\n",
    "scores_all = {int(it[\"id\"]): float(it[\"score\"]) for it in items}\n",
    "\n",
    "df[\"sim_qwen\"] = df[\"id\"].map(scores_all)\n",
    "\n",
    "# Quick view of top matches\n",
    "df.sort_values(\"sim_qwen\", ascending=False)[[\"id\",\"job_title_clean\",\"sim_qwen\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c177e1-bc58-43be-a4d6-633a7021820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 200 chars: [{\"id\": 9001, \"score\": 0.95}]\n",
      "Items returned: 1 Expected: 104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>sim_qwen_fs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    job_title_clean  sim_qwen_fs\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...          NaN\n",
       "1   2  Native English Teacher at EPIK (English Progra...          NaN\n",
       "2   3              Aspiring Human Resources Professional          NaN\n",
       "3   4             People Development Coordinator at Ryan          NaN\n",
       "4   5    Advisory Board Member at Celal Bayar University          NaN\n",
       "5   6                Aspiring Human Resources Specialist          NaN\n",
       "6   7  Student at Humber College and Aspiring Human R...          NaN\n",
       "7   8                               HR Senior Specialist          NaN\n",
       "8   9  Student at Humber College and Aspiring Human R...          NaN\n",
       "9  10  Seeking Human Resources HRIS and Generalist Po...          NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1) Inspect what came back\n",
    "print(\"First 200 chars:\", json_text_fs[:200])   # from the previous step\n",
    "print(\"Items returned:\", len(items_fs), \"Expected:\", len(df))\n",
    "\n",
    "# 2) If counts match, map by order (fastest way to eliminate NaNs)\n",
    "if len(items_fs) == len(df):\n",
    "    df = df.reset_index(drop=True)  # ensure same order used to build the prompt\n",
    "    df[\"sim_qwen_fs\"] = [float(obj[\"score\"]) for obj in items_fs]\n",
    "else:\n",
    "    # If counts don't match, keep whatever matched IDs we do have (partial fill)\n",
    "    scores_fs = {int(it[\"id\"]): float(it[\"score\"]) for it in items_fs if \"id\" in it and \"score\" in it}\n",
    "    df[\"sim_qwen_fs\"] = df[\"id\"].map(scores_fs)\n",
    "\n",
    "# 3) Quick check\n",
    "df.sort_values(\"sim_qwen_fs\", ascending=False)[[\"id\",\"job_title_clean\",\"sim_qwen_fs\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11c350",
   "metadata": {},
   "source": [
    "### Configuration & Constants\n",
    "Centralize hyperparameters, paths, and seeds for reproducible runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13dc99d7-2d2c-4f39-839d-6e419f414462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>sim_qwen_fs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    job_title_clean  sim_qwen_fs\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...          NaN\n",
       "1   2  Native English Teacher at EPIK (English Progra...          NaN\n",
       "2   3              Aspiring Human Resources Professional          NaN\n",
       "3   4             People Development Coordinator at Ryan          NaN\n",
       "4   5    Advisory Board Member at Celal Bayar University          NaN\n",
       "5   6                Aspiring Human Resources Specialist          NaN\n",
       "6   7  Student at Humber College and Aspiring Human R...          NaN\n",
       "7   8                               HR Senior Specialist          NaN\n",
       "8   9  Student at Humber College and Aspiring Human R...          NaN\n",
       "9  10  Seeking Human Resources HRIS and Generalist Po...          NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Define few-shot anchors\n",
    "EXAMPLES = [\n",
    "    {\"cands\": [{\"id\": 9001, \"title\": \"Aspiring Human Resources Specialist\"}],\n",
    "     \"json\":  [{\"id\": 9001, \"score\": 0.95}]},\n",
    "    {\"cands\": [{\"id\": 9002, \"title\": \"Retail Manager\"}],\n",
    "     \"json\":  [{\"id\": 9002, \"score\": 0.15}]},\n",
    "]\n",
    "\n",
    "# 2) Build compact prompt with examples serialized as TRUE JSON\n",
    "def build_prompt_all_fewshot(df, role=\"Aspiring Human Resources Specialist\"):\n",
    "    ex_blocks = []\n",
    "    for ex in EXAMPLES:\n",
    "        ex_lines = [\"Example:\", \"Candidates:\"]\n",
    "        for c in ex[\"cands\"]:\n",
    "            ex_lines.append(f'- id={c[\"id\"]}, title=\"{c[\"title\"]}\"')\n",
    "        ex_json = json.dumps(ex[\"json\"], ensure_ascii=False)   # << correct JSON (double quotes)\n",
    "        ex_lines.append(f\"JSON: {ex_json}\\n\")\n",
    "        ex_blocks.append(\"\\n\".join(ex_lines))\n",
    "\n",
    "    cands = [{\"id\": int(r.id), \"title\": short_title(str(r.job_title_clean))} for r in df.itertuples()]\n",
    "    header = (\n",
    "        \"You are a recruiting assistant.\\n\"\n",
    "        + \"\\n\".join(ex_blocks)\n",
    "        + f'Rank these {len(cands)} candidates for the role \"{role}\" by fit.\\n'\n",
    "        f\"Return ONLY a JSON array with exactly {len(cands)} objects \"\n",
    "        '( {\"id\": <int>, \"score\": <float in [0,1]>} ), one per candidate in the SAME ORDER.\\n'\n",
    "        \"No text before or after the JSON.\\n\\nCandidates:\\n\"\n",
    "    )\n",
    "    body = \"\\n\".join([f'- id={c[\"id\"]}, title=\"{c[\"title\"]}\"' for c in cands])\n",
    "    return header + body + \"\\n\\nJSON:\"\n",
    "\n",
    "# 3) Generate once, extract balanced array, parse strictly, attach\n",
    "prompt_fs = build_prompt_all_fewshot(df)\n",
    "raw_fs = pipe(\n",
    "    prompt_fs,\n",
    "    max_new_tokens=1536,\n",
    "    do_sample=False,\n",
    "    pad_token_id=pipe.tokenizer.eos_token_id if hasattr(pipe, \"tokenizer\") else None,\n",
    "    return_full_text=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "json_text_fs = extract_balanced_json_array(raw_fs)  # grabs the first complete [...] block\n",
    "items_fs = json.loads(json_text_fs)                 # strict JSON parsing\n",
    "scores_fs = {int(it[\"id\"]): float(it[\"score\"]) for it in items_fs}\n",
    "\n",
    "df[\"sim_qwen_fs\"] = df[\"id\"].map(scores_fs)\n",
    "df.sort_values(\"sim_qwen_fs\", ascending=False)[[\"id\",\"job_title_clean\",\"sim_qwen_fs\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0143725-e357-4a19-be21-a3ebc45e2e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>sim_qwen_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>SVP, CHRO, Marketing &amp; Communications, CSR Off...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Human Resources Coordinator at InterContinenta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                    job_title_clean  sim_qwen_hr\n",
       "0    1  2019 C.T. Bauer College of Business Graduate (...         0.95\n",
       "2    3              Aspiring Human Resources Professional         0.95\n",
       "1    2  Native English Teacher at EPIK (English Progra...         0.20\n",
       "3    4             People Development Coordinator at Ryan          NaN\n",
       "4    5    Advisory Board Member at Celal Bayar University          NaN\n",
       "5    6                Aspiring Human Resources Specialist          NaN\n",
       "6    7  Student at Humber College and Aspiring Human R...          NaN\n",
       "7    8                               HR Senior Specialist          NaN\n",
       "8    9  Student at Humber College and Aspiring Human R...          NaN\n",
       "9   10  Seeking Human Resources HRIS and Generalist Po...          NaN\n",
       "10  11                      Student at Chapman University          NaN\n",
       "11  12  SVP, CHRO, Marketing & Communications, CSR Off...          NaN\n",
       "12  13  Human Resources Coordinator at InterContinenta...          NaN\n",
       "13  14  2019 C.T. Bauer College of Business Graduate (...          NaN\n",
       "14  15  2019 C.T. Bauer College of Business Graduate (...          NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, re\n",
    "\n",
    "# reuse short_title(...) and extract_balanced_json_array(...) from earlier\n",
    "def short_title(s: str, max_words: int = 8):\n",
    "    ws = re.findall(r\"[A-Za-z0-9]+\", s or \"\")\n",
    "    return \" \".join(ws[:max_words])\n",
    "\n",
    "def extract_balanced_json_array(text: str) -> str:\n",
    "    start = text.find(\"[\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No '[' found in model output.\")\n",
    "    depth = 0\n",
    "    for i, ch in enumerate(text[start:], start=start):\n",
    "        if ch == \"[\":\n",
    "            depth += 1\n",
    "        elif ch == \"]\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return text[start:i+1]\n",
    "    raise ValueError(\"Unbalanced JSON array (truncated).\")\n",
    "\n",
    "# A) Few-shot anchors with TRUE JSON (double quotes)\n",
    "EXAMPLES = [\n",
    "    ( [{\"id\": 9001, \"title\": \"Aspiring Human Resources Specialist\"}],\n",
    "      [{\"id\": 9001, \"score\": 0.95}] ),\n",
    "    ( [{\"id\": 9002, \"title\": \"Retail Store Manager\"}],\n",
    "      [{\"id\": 9002, \"score\": 0.20}] ),\n",
    "    ( [{\"id\": 9003, \"title\": \"Student, Business Administration\"}],\n",
    "      [{\"id\": 9003, \"score\": 0.25}] ),\n",
    "]\n",
    "\n",
    "# B) Build rubric prompt: clear instructions + positives/negatives + JSON-only\n",
    "def build_prompt_hr_rubric(df, role=\"Human Resources (Generalist / Recruiting)\"):\n",
    "    ex_blocks = []\n",
    "    for cands, lbl in EXAMPLES:\n",
    "        ex = [\"Example:\", \"Candidates:\"]\n",
    "        for c in cands:\n",
    "            ex.append(f'- id={c[\"id\"]}, title=\"{c[\"title\"]}\"')\n",
    "        ex.append(\"JSON: \" + json.dumps(lbl, ensure_ascii=False) + \"\\n\")\n",
    "        ex_blocks.append(\"\\n\".join(ex))\n",
    "\n",
    "    # compact candidate list\n",
    "    cands = [{\"id\": int(r.id), \"title\": short_title(str(r.job_title_clean))} for r in df.itertuples()]\n",
    "\n",
    "    rubric = (\n",
    "        \"You are ranking candidates STRICTLY for Human Resources roles.\\n\"\n",
    "        \"Scoring rules (0–1):\\n\"\n",
    "        \"• 0.80–1.00: Clear HR (e.g., HR Specialist, HR Generalist, Recruiter, Talent Acquisition).\\n\"\n",
    "        \"• 0.40–0.70: Possibly HR-adjacent (People Ops, Office/People Coordinator with HR hints).\\n\"\n",
    "        \"• 0.00–0.30: Not HR (e.g., Teacher, Student only, Board/Advisory, unrelated majors/roles).\\n\"\n",
    "        \"Penalize strongly if the title includes Teacher, Professor, Student (without HR), Advisor/Advisory/Board.\\n\"\n",
    "        \"Return ONLY JSON. Do not output any text before or after JSON.\\n\"\n",
    "    )\n",
    "\n",
    "    header = rubric + \"\\n\".join(ex_blocks) + \\\n",
    "        f'Rank these {len(cands)} candidates for \"{role}\" by fit.\\n' \\\n",
    "        f\"Return ONLY a JSON array with exactly {len(cands)} objects \" \\\n",
    "        '( {\"id\": <int>, \"score\": <float in [0,1]>} ), one per candidate in the SAME ORDER.\\n\\n' \\\n",
    "        \"Candidates:\\n\"\n",
    "    body = \"\\n\".join([f'- id={c[\"id\"]}, title=\"{c[\"title\"]}\"' for c in cands])\n",
    "    return header + body + \"\\n\\nJSON:\"\n",
    "\n",
    "# C) Generate once, parse strictly, and attach scores (map by order if counts match)\n",
    "prompt_hr = build_prompt_hr_rubric(df)\n",
    "raw_hr = pipe(\n",
    "    prompt_hr,\n",
    "    max_new_tokens=1792,                  # ample room for 104 items\n",
    "    do_sample=False,\n",
    "    pad_token_id=getattr(pipe.tokenizer, \"eos_token_id\", None),\n",
    "    return_full_text=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "json_slice = extract_balanced_json_array(raw_hr)\n",
    "\n",
    "# Regex-tolerant parse: accepts id/score with or without quotes, ignores trailing commas/spaces\n",
    "pairs = re.findall(\n",
    "    r'\\{\\s*\"?id\"?\\s*:\\s*(\\d+)\\s*,\\s*\"?score\"?\\s*:\\s*([0-9]*\\.?[0-9]+)\\s*\\}',\n",
    "    json_slice\n",
    ")\n",
    "\n",
    "items_hr = [{\"id\": int(i), \"score\": float(s)} for i, s in pairs]\n",
    "\n",
    "# If counts match, assign by order (fastest & avoids NaNs); else map by id\n",
    "if len(items_hr) == len(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"sim_qwen_hr\"] = [o[\"score\"] for o in items_hr]\n",
    "else:\n",
    "    scores_hr = {o[\"id\"]: o[\"score\"] for o in items_hr}\n",
    "    df[\"sim_qwen_hr\"] = df[\"id\"].map(scores_hr)\n",
    "\n",
    "df.sort_values(\"sim_qwen_hr\", ascending=False)[[\"id\",\"job_title_clean\",\"sim_qwen_hr\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58da6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Add an **Experiment Card** cell (model, tokenizer, data snapshot, hyperparams, seed, hardware).\n",
    "- Log runs with **wandb/MLflow** and save evaluation plots/tables.\n",
    "- Provide robust **chat inference demos** (multi-turn, system prompts, streaming where relevant).\n",
    "- If applicable, include **safety/bias checks** with example outputs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
